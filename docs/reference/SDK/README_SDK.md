# Claude Code SDK Bridge

High-performance bridge between Python RP automation and Claude Code SDK.

## Features

âœ… **10-50x Faster** - No subprocess spawning
âœ… **Real-time Streaming** - See responses as they generate
âœ… **Proper Caching** - TIER_1 files cached automatically
âœ… **Session Management** - Built-in conversation history
âœ… **Cache Statistics** - See exactly what's being cached and savings

## Installation

### 1. Install Node.js (if not already installed)

Download from: https://nodejs.org/ (LTS version recommended)

Verify installation:
```bash
node --version
npm --version
```

### 2. Install Dependencies

From the `work_in_progress` directory:

```bash
cd "C:\Users\green\Desktop\RP Claude Code\work_in_progress"
npm install
```

This will install `@anthropic-ai/claude-code` SDK.

### 3. Test the Bridge

Test the SDK bridge directly:

```bash
cd "C:\Users\green\Desktop\RP Claude Code\work_in_progress"
python clients/claude_sdk.py
```

You should see a test query execute successfully.

## Usage

### From Python (Simple)

```python
from work_in_progress.clients.claude_sdk import ClaudeSDKClient

# Create client
client = ClaudeSDKClient()

# Stream a response
for chunk in client.query("Hello, Claude!"):
    print(chunk, end='', flush=True)

# Get cache stats
stats = client.get_cache_stats()
print(stats)

# Close
client.close()
```

### From Python (With Context Manager)

```python
from work_in_progress.clients.claude_sdk import ClaudeSDKClient

with ClaudeSDKClient() as client:
    # First query with caching
    cached_context = "... your TIER_1 files ..."
    message = "... user message ..."

    for chunk in client.query(message, cached_context=cached_context):
        print(chunk, end='', flush=True)

    # Subsequent queries reuse cache
    for chunk in client.query("Follow-up question"):
        print(chunk, end='', flush=True)

    # See savings
    print(client.get_cache_stats())
```

### Integration with tui_bridge.py

The bridge can be integrated into `tui_bridge.py` by replacing the Claude CLI calls:

```python
from work_in_progress.clients.claude_sdk import ClaudeSDKClient

# In main() function, create SDK client
sdk_client = ClaudeSDKClient(cwd=rp_dir)

# Then in the message processing loop:
if use_sdk_mode and sdk_client:
    # Use automation to build prompts
    cached_context, dynamic_prompt, loaded_entities = run_automation_with_caching(message, rp_dir)

    # Query SDK (streaming)
    response = ""
    for chunk in sdk_client.query(dynamic_prompt, cached_context=cached_context):
        response += chunk
        # Could stream to TUI here if desired

    # Get stats
    stats = sdk_client.get_cache_stats()
    if stats:
        print(stats)
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python (tui_bridge.py)                 â”‚
â”‚  - Automation (TIER_1/2/3)              â”‚
â”‚  - Entity tracking                      â”‚
â”‚  - Time calculation                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Python API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python Wrapper (claude_sdk.py)         â”‚
â”‚  - ClaudeSDKClient class                â”‚
â”‚  - Streaming support                    â”‚
â”‚  - Cache stats                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ JSON over stdin/stdout
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node.js Bridge (claude_sdk_bridge.mjs) â”‚
â”‚  - Persistent process                   â”‚
â”‚  - SDK integration                      â”‚
â”‚  - Session management                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Direct SDK calls
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Claude Code SDK (@anthropic-ai)        â”‚
â”‚  - Native caching                       â”‚
â”‚  - Conversation history                 â”‚
â”‚  - Real-time streaming                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Benefits vs CLI Mode

| Feature | CLI Mode (`claude -c`) | SDK Mode (New) |
|---------|----------------------|----------------|
| **Speed** | ~1-2s startup per call | ~50ms (no startup) |
| **Streaming** | No (buffered) | Yes (real-time) |
| **Cache Control** | Automatic (opaque) | Explicit control |
| **Cache Stats** | Not visible | Detailed reporting |
| **Session Management** | Flag file based | Built-in |
| **Error Handling** | Process exit codes | Structured errors |
| **Memory Usage** | New process each time | Persistent (lower) |

## Caching Strategy

The SDK bridge implements optimal caching:

1. **TIER_1 Files** â†’ `cached_context` â†’ Cached by Claude API
   - Author's notes, story genome, scene notes, character sheets
   - Cached across all messages in session
   - ~90% cache hit rate after first message

2. **TIER_2 Files** â†’ `message` â†’ Not cached (changes every 4 responses)
   - Guidelines, style guides
   - Small enough to not need caching

3. **TIER_3 Files** â†’ `message` â†’ Not cached (conditional)
   - Entity cards, triggered content
   - Changes based on context

## Cache Statistics

After each query, you can see detailed stats:

```
ğŸ“Š Token Usage:
  Input: 15,234 tokens
  Output: 456 tokens
  ğŸ’¾ Cache Read: 12,000 tokens
  ğŸ’° Savings: 78.8% (HIT)
```

This shows:
- Input tokens (not including cached)
- Output tokens generated
- Cache hit tokens (read from cache)
- Savings percentage

## Troubleshooting

### "Node.js not found"

Install Node.js from https://nodejs.org/

### "SDK bridge script not found"

Make sure you're running from the correct directory and package.json exists.

### "Failed to initialize"

Check that `@anthropic-ai/claude-code` is installed:
```bash
npm list @anthropic-ai/claude-code
```

If not installed:
```bash
npm install
```

### Process hangs

The SDK bridge runs as a persistent process. If it hangs:
1. Close Python script
2. Check for orphaned node processes
3. Restart

### Debugging

Run the Node.js bridge directly to see raw output:
```bash
node work_in_progress/clients/claude_sdk_bridge.mjs
```

Then send test commands via stdin:
```json
{"command":"query","message":"Hello!"}
```

## Performance Tips

1. **Keep sessions alive** - Reuse the same `ClaudeSDKClient` instance
2. **Cache TIER_1 aggressively** - These rarely change
3. **Stream to UI** - Don't wait for full response before displaying
4. **Monitor cache stats** - Adjust what gets cached based on hit rates

## Next Steps

To fully integrate:

1. Add config option to `tui_bridge.py` for SDK mode
2. Replace subprocess calls with SDK client
3. Stream chunks to TUI in real-time
4. Display cache savings in UI

See the comments in the code for integration points!
