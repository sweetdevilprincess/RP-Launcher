# Quick Start: SDK Bridge Setup

Get your RP system running with the high-performance SDK bridge in under 5 minutes!

## Step 1: Install Node.js

If you don't have Node.js installed:

1. Go to https://nodejs.org/
2. Download the **LTS version** (left button)
3. Run the installer (default settings are fine)
4. Verify installation:

```bash
node --version
npm --version
```

You should see version numbers (e.g., `v20.11.0` and `10.2.4`).

## Step 2: Install SDK Dependencies

Open a terminal in the `work_in_progress` folder:

```bash
cd "C:\Users\green\Desktop\RP Claude Code\work_in_progress"
npm install
```

This downloads `@anthropic-ai/claude-code` SDK. You should see:

```
added 1 package, and audited 2 packages in 3s
```

## Step 3: Test the SDK Bridge

Run the test to make sure everything works:

```bash
python clients/claude_sdk.py
```

Expected output:
```
Testing Claude SDK Client...

Sending test query...
Hello from the SDK!

ðŸ“Š Token Usage:
  Input: 23 tokens
  Output: 8 tokens

âœ… SDK bridge is working!
```

If you see this, **you're ready to go!**

## Step 4: Use SDK in Your Bridge (Optional)

To integrate with `tui_bridge.py`, add this near the top of your bridge file:

```python
# Add after other imports
from work_in_progress.clients.claude_sdk import ClaudeSDKClient

# Add a config flag
use_sdk_mode = True  # Set to True to use SDK instead of CLI

# In main(), create SDK client if enabled
if use_sdk_mode:
    sdk_client = ClaudeSDKClient(cwd=rp_dir)
    print("ðŸš€ SDK mode enabled - high performance!")
else:
    sdk_client = None
    print("ðŸ“Ÿ CLI mode enabled - standard performance")
```

Then in your message processing loop, replace the `claude` CLI call:

```python
# Instead of this:
# result = claude_client.run_claude(enhanced_message, cwd=rp_dir, continue_conversation=True)

# Use this:
if use_sdk_mode and sdk_client:
    response = ""
    for chunk in sdk_client.query(dynamic_prompt, cached_context=cached_context):
        response += chunk
        # Optionally stream to TUI here

    # Show cache stats
    stats = sdk_client.get_cache_stats()
    if stats:
        print(stats)
else:
    # Fall back to CLI mode
    result = claude_client.run_claude(...)
    response = result.stdout.strip()
```

## Comparison: Before vs After

### Before (CLI Mode)
```
ðŸ¤– Sending to Claude Code...
[Wait 1-2 seconds for process to start]
[Wait for full response]
âœ“ Response received (3.2 seconds)
```

### After (SDK Mode)
```
ðŸš€ Sending to Claude Code SDK...
âœ“ Initialized (0.05 seconds)
[Streaming response appears immediately]
âœ“ Complete (0.8 seconds)

ðŸ“Š Token Usage:
  Input: 15,234 tokens
  Output: 456 tokens
  ðŸ’¾ Cache Read: 12,000 tokens
  ðŸ’° Savings: 78.8% (HIT)
```

## Benefits You'll See

1. **Faster responses** - ~10x faster startup, ~3x faster overall
2. **Real-time streaming** - See text appear as it's generated
3. **Cache visibility** - Know exactly what's being cached
4. **Cost savings** - 90% reduction in cached content costs
5. **Better sessions** - More reliable conversation continuity

## Troubleshooting

### "npm: command not found"
- Node.js wasn't installed or isn't in PATH
- Restart your terminal after installing Node.js
- Or reboot your computer

### "Cannot find module '@anthropic-ai/claude-code'"
- Run `npm install` in the `work_in_progress` directory
- Make sure `package.json` exists in that folder

### SDK test fails with timeout
- Check your internet connection
- Claude API might be down (check status.anthropic.com)
- Make sure you have Claude Code already installed: `claude --version`

### Bridge hangs
- The SDK runs as a persistent process
- If it hangs, close Python and restart
- Check for orphaned `node` processes in Task Manager

## Next Steps

Once the SDK is working:

1. Integrate into `tui_bridge.py` with the code above
2. Add a config toggle in your TUI settings for SDK vs CLI mode
3. Monitor cache hit rates and adjust TIER_1 content
4. Consider streaming responses directly to your TUI for real-time display

## Need Help?

Check the full documentation in `README_SDK.md` for:
- Detailed architecture
- Advanced configuration
- Performance tuning
- Integration examples

Happy RP'ing with blazing fast responses! ðŸš€
